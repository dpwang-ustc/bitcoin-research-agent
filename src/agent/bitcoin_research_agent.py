"""
Bitcoin Research Agent - LangGraph è‡ªé©±åŠ¨ç ”ç©¶æ™ºèƒ½ä½“

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨åŒ–æ•°æ®é‡‡é›†å’Œå¤„ç†
2. å¤šç»´åº¦å¹¶è¡Œåˆ†æ
3. AI ç”Ÿæˆå¸‚åœºæ´å¯Ÿ
4. è‡ªåŠ¨ç”Ÿæˆå’Œå‘å¸ƒæŠ¥å‘Š
5. è‡ªç„¶è¯­è¨€äº¤äº’

åŸºäº LangGraph çš„çŠ¶æ€æœºæ¶æ„ï¼Œå®ç°å®Œå…¨å¯æ§çš„å·¥ä½œæµã€‚

ä½œè€…ï¼šBitcoin Research Agent Team
æ—¥æœŸï¼š2025-10-26
"""

import os
import sys
from datetime import datetime
from typing import TypedDict, List, Dict, Any, Optional, Annotated
import operator

# LangGraph imports
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# LangChain LLM imports
try:
    from langchain_openai import ChatOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("Warning: langchain-openai not installed")

# ç°æœ‰æ¨¡å—
from src.data_loader import load_bitcoin_data
from src.feature_engineering import FeatureEngineer
from src.model.market_regime import MarketRegimeIdentifier
from src.analysis.volatility_analyzer import VolatilityAnalyzer
from src.analysis.sentiment_analyzer import SentimentAnalyzer
from src.analysis.capital_flow_analyzer import CapitalFlowAnalyzer
from src.model.agent_reasoner import MarketInsightAgent
from src.reports.weekly_report_generator import WeeklyReportGenerator

import pandas as pd


# ==================== çŠ¶æ€å®šä¹‰ ====================

class ResearchState(TypedDict):
    """ç ”ç©¶ Agent çš„çŠ¶æ€"""
    # è¾“å…¥
    user_input: str
    task_type: str  # "full_analysis", "quick_query", "generate_report"
    
    # æ•°æ®
    market_data: Optional[pd.DataFrame]
    processed_data: Optional[pd.DataFrame]
    
    # åˆ†æç»“æœ
    regime_analysis: Optional[Dict[str, Any]]
    volatility_analysis: Optional[Dict[str, Any]]
    sentiment_analysis: Optional[Dict[str, Any]]
    capital_analysis: Optional[Dict[str, Any]]
    
    # AI æ´å¯Ÿ
    ai_insights: Optional[str]
    
    # è¾“å‡º
    report: Optional[str]
    response: Optional[str]
    
    # å…ƒæ•°æ®
    messages: Annotated[List, operator.add]  # å¯¹è¯å†å²
    current_step: str  # å½“å‰æ­¥éª¤
    error: Optional[str]  # é”™è¯¯ä¿¡æ¯


# ==================== BitcoinResearchAgent ä¸»ç±» ====================

class BitcoinResearchAgent:
    """
    æ¯”ç‰¹å¸ç ”ç©¶æ™ºèƒ½ä½“ï¼ˆLangGraph å®ç°ï¼‰
    
    ç‰¹ç‚¹ï¼š
    1. è‡ªåŠ¨åŒ–ï¼šè‡ªåŠ¨æ‰§è¡Œå®Œæ•´çš„ç ”ç©¶æµç¨‹
    2. å¯æ§ï¼šæ˜ç¡®å®šä¹‰çš„å·¥ä½œæµï¼Œå¯è§†åŒ–
    3. å¹¶è¡Œï¼šæ”¯æŒå¤šä¸ªåˆ†æä»»åŠ¡å¹¶è¡Œæ‰§è¡Œ
    4. æ™ºèƒ½ï¼šAI é©±åŠ¨çš„æ´å¯Ÿç”Ÿæˆ
    5. äº¤äº’ï¼šæ”¯æŒè‡ªç„¶è¯­è¨€å¯¹è¯
    """
    
    def __init__(
        self,
        llm_provider: str = "openai",
        llm_model: str = "gpt-4o-mini",
        api_key: Optional[str] = None,
        verbose: bool = True
    ):
        """
        åˆå§‹åŒ–ç ”ç©¶ Agent
        
        Args:
            llm_provider: LLM æä¾›å•†ï¼ˆopenai/anthropicï¼‰
            llm_model: æ¨¡å‹åç§°
            api_key: API å¯†é’¥
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        self.verbose = verbose
        self.log("åˆå§‹åŒ– Bitcoin Research Agent...")
        
        # åˆå§‹åŒ– LLM
        self.llm = self._init_llm(llm_provider, llm_model, api_key)
        
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        self.feature_engineer = FeatureEngineer(verbose=False)
        self.market_regime = MarketRegimeIdentifier(n_regimes=4, method='kmeans', verbose=False)
        self.volatility_analyzer = VolatilityAnalyzer(verbose=False)
        self.sentiment_analyzer = SentimentAnalyzer(verbose=False)
        self.capital_analyzer = CapitalFlowAnalyzer(verbose=False)
        self.market_insight_agent = MarketInsightAgent(
            provider=llm_provider,
            model=llm_model,
            api_key=api_key,
            verbose=False
        )
        
        # æ„å»º LangGraph å·¥ä½œæµ
        self.workflow = self._build_workflow()
        self.app = self.workflow.compile()
        
        self.log("âœ… Bitcoin Research Agent åˆå§‹åŒ–å®Œæˆ")
    
    def log(self, message: str):
        """æ‰“å°æ—¥å¿—"""
        if self.verbose:
            print(f"[Agent] {message}")
    
    def _init_llm(self, provider: str, model: str, api_key: Optional[str]):
        """åˆå§‹åŒ– LLM"""
        if provider == "openai":
            if not OPENAI_AVAILABLE:
                raise ImportError("Please install: pip install langchain-openai")
            
            api_key = api_key or os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OpenAI API key not found")
            
            return ChatOpenAI(
                model=model,
                api_key=api_key,
                temperature=0.7
            )
        else:
            raise ValueError(f"Unsupported provider: {provider}")
    
    # ==================== èŠ‚ç‚¹å‡½æ•° ====================
    
    def _node_route_task(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹ï¼šä»»åŠ¡è·¯ç”±"""
        self.log(f"è·¯ç”±ä»»åŠ¡: {state['user_input']}")
        
        # ä½¿ç”¨ LLM åˆ¤æ–­ä»»åŠ¡ç±»å‹
        messages = [
            SystemMessage(content="""ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡è·¯ç”±å™¨ã€‚æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œåˆ¤æ–­ä»»åŠ¡ç±»å‹ã€‚

ä»»åŠ¡ç±»å‹ï¼š
- "full_analysis": éœ€è¦å®Œæ•´çš„æ•°æ®é‡‡é›†å’Œåˆ†æï¼ˆå¦‚"ç”Ÿæˆå‘¨æŠ¥"ã€"å®Œæ•´åˆ†æ"ï¼‰
- "quick_query": ç®€å•æŸ¥è¯¢ï¼ˆå¦‚"æ¯”ç‰¹å¸ä»·æ ¼"ã€"å¸‚åœºæƒ…ç»ªå¦‚ä½•"ï¼‰
- "generate_report": ç”ŸæˆæŠ¥å‘Šï¼ˆå¦‚"ç”ŸæˆæŠ¥å‘Š"ã€"åˆ›å»ºå‘¨æŠ¥"ï¼‰

åªå›ç­”ä»»åŠ¡ç±»å‹ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""),
            HumanMessage(content=state['user_input'])
        ]
        
        try:
            response = self.llm.invoke(messages)
            task_type = response.content.strip().lower()
            
            if "full" in task_type:
                state['task_type'] = "full_analysis"
            elif "report" in task_type:
                state['task_type'] = "generate_report"
            else:
                state['task_type'] = "quick_query"
            
        except Exception as e:
            self.log(f"è·¯ç”±å¤±è´¥ï¼Œé»˜è®¤ä¸º full_analysis: {e}")
            state['task_type'] = "full_analysis"
        
        state['current_step'] = "task_routed"
        state['messages'] = [AIMessage(content=f"ä»»åŠ¡ç±»å‹ï¼š{state['task_type']}")]
        
        return state
    
    def _node_collect_data(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹ï¼šæ•°æ®é‡‡é›†"""
        self.log("é‡‡é›†å¸‚åœºæ•°æ®...")
        state['current_step'] = "collecting_data"
        
        try:
            # åŠ è½½æ¯”ç‰¹å¸æ•°æ®
            df = load_bitcoin_data(start='2023-01-01')
            state['market_data'] = df
            state['messages'].append(AIMessage(content=f"âœ… æ•°æ®é‡‡é›†å®Œæˆï¼Œå…± {len(df)} è¡Œ"))
            
        except Exception as e:
            state['error'] = f"æ•°æ®é‡‡é›†å¤±è´¥: {str(e)}"
            state['messages'].append(AIMessage(content=f"âŒ æ•°æ®é‡‡é›†å¤±è´¥: {str(e)}"))
        
        return state
    
    def _node_process_data(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹ï¼šæ•°æ®å¤„ç†å’Œç‰¹å¾å·¥ç¨‹"""
        self.log("å¤„ç†æ•°æ®å’Œæå–ç‰¹å¾...")
        state['current_step'] = "processing_data"
        
        try:
            df = state['market_data']
            
            # ç‰¹å¾å·¥ç¨‹
            df_processed = self.feature_engineer.process_pipeline(
                df,
                clean=True,
                add_features=True,
                detect_outliers=False,
                handle_missing=True
            )
            
            state['processed_data'] = df_processed
            state['messages'].append(AIMessage(content=f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œå…± {len(df_processed.columns)} ä¸ªç‰¹å¾"))
            
        except Exception as e:
            state['error'] = f"æ•°æ®å¤„ç†å¤±è´¥: {str(e)}"
            state['messages'].append(AIMessage(content=f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {str(e)}"))
        
        return state
    
    def _node_analyze_regime(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹ï¼šå¸‚åœºçŠ¶æ€åˆ†æ"""
        self.log("åˆ†æå¸‚åœºçŠ¶æ€...")
        state['current_step'] = "analyzing_regime"
        
        try:
            df = state['processed_data']
            
            # å¸‚åœºçŠ¶æ€è¯†åˆ«
            df_regime = self.market_regime.fit(df, method='kmeans')
            regime_stats = self.market_regime.analyze_regime_characteristics(df_regime)
            
            state['regime_analysis'] = {
                'data': df_regime,
                'stats': regime_stats
            }
            state['messages'].append(AIMessage(content="âœ… å¸‚åœºçŠ¶æ€åˆ†æå®Œæˆ"))
            
        except Exception as e:
            self.log(f"å¸‚åœºçŠ¶æ€åˆ†æå¤±è´¥: {e}")
            state['regime_analysis'] = None
        
        return state
    
    def _node_analyze_volatility(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹ï¼šæ³¢åŠ¨ç‡åˆ†æ"""
        self.log("åˆ†ææ³¢åŠ¨ç‡...")
        state['current_step'] = "analyzing_volatility"
        
        try:
            df = state['regime_analysis']['data'] if state.get('regime_analysis') else state['processed_data']
            
            # æ³¢åŠ¨ç‡åˆ†æ
            df_vol = self.volatility_analyzer.process_pipeline(df)
            
            state['volatility_analysis'] = {'data': df_vol}
            state['messages'].append(AIMessage(content="âœ… æ³¢åŠ¨ç‡åˆ†æå®Œæˆ"))
            
        except Exception as e:
            self.log(f"æ³¢åŠ¨ç‡åˆ†æå¤±è´¥: {e}")
            state['volatility_analysis'] = None
        
        return state
    
    def _node_analyze_sentiment(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹ï¼šæƒ…ç»ªåˆ†æ"""
        self.log("åˆ†æå¸‚åœºæƒ…ç»ª...")
        state['current_step'] = "analyzing_sentiment"
        
        try:
            df = state['volatility_analysis']['data'] if state.get('volatility_analysis') else state['processed_data']
            
            # æƒ…ç»ªåˆ†æ
            df_sentiment = self.sentiment_analyzer.process_pipeline(df)
            
            state['sentiment_analysis'] = {'data': df_sentiment}
            state['messages'].append(AIMessage(content="âœ… æƒ…ç»ªåˆ†æå®Œæˆ"))
            
        except Exception as e:
            self.log(f"æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            state['sentiment_analysis'] = None
        
        return state
    
    def _node_analyze_capital(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹ï¼šèµ„é‡‘æµå‘åˆ†æ"""
        self.log("åˆ†æèµ„é‡‘æµå‘...")
        state['current_step'] = "analyzing_capital"
        
        try:
            df = state['sentiment_analysis']['data'] if state.get('sentiment_analysis') else state['processed_data']
            
            # èµ„é‡‘æµå‘åˆ†æ
            df_capital = self.capital_analyzer.process_pipeline(df)
            
            state['capital_analysis'] = {'data': df_capital}
            state['messages'].append(AIMessage(content="âœ… èµ„é‡‘æµå‘åˆ†æå®Œæˆ"))
            
        except Exception as e:
            self.log(f"èµ„é‡‘æµå‘åˆ†æå¤±è´¥: {e}")
            state['capital_analysis'] = None
        
        return state
    
    def _node_generate_insights(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹ï¼šç”Ÿæˆ AI æ´å¯Ÿ"""
        self.log("ç”Ÿæˆ AI æ´å¯Ÿ...")
        state['current_step'] = "generating_insights"
        
        try:
            # å‡†å¤‡æ•°æ®æ‘˜è¦
            df_final = state['capital_analysis']['data']
            
            # æå–å…³é”®ç»Ÿè®¡
            stats = self._extract_key_stats(df_final)
            
            # ä½¿ç”¨ AI ç”Ÿæˆæ´å¯Ÿ
            insights = self.market_insight_agent.analyze_market_data(stats)
            
            state['ai_insights'] = insights
            state['messages'].append(AIMessage(content="âœ… AI æ´å¯Ÿç”Ÿæˆå®Œæˆ"))
            
        except Exception as e:
            self.log(f"AI æ´å¯Ÿç”Ÿæˆå¤±è´¥: {e}")
            state['ai_insights'] = "æ— æ³•ç”Ÿæˆ AI æ´å¯Ÿ"
        
        return state
    
    def _node_generate_report(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹ï¼šç”ŸæˆæŠ¥å‘Š"""
        self.log("ç”Ÿæˆå®Œæ•´æŠ¥å‘Š...")
        state['current_step'] = "generating_report"
        
        try:
            # ä½¿ç”¨ç°æœ‰çš„å‘¨æŠ¥ç”Ÿæˆå™¨
            generator = WeeklyReportGenerator(
                data_path=None,  # ä½¿ç”¨å†…å­˜ä¸­çš„æ•°æ®
                use_ai=True,
                verbose=False
            )
            
            # ä½¿ç”¨å·²å¤„ç†çš„æ•°æ®
            generator.df = state['capital_analysis']['data']
            generator.calculate_weekly_stats()
            
            # ç”ŸæˆæŠ¥å‘Š
            report = generator._generate_report_content()
            
            state['report'] = report
            state['response'] = f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ\n\n{report[:500]}...\n\n[å®Œæ•´æŠ¥å‘Šå·²ç”Ÿæˆ]"
            state['messages'].append(AIMessage(content="âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ"))
            
        except Exception as e:
            self.log(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            state['report'] = None
            state['response'] = f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
        
        return state
    
    def _node_quick_response(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹ï¼šå¿«é€Ÿå“åº”ï¼ˆç®€å•æŸ¥è¯¢ï¼‰"""
        self.log("ç”Ÿæˆå¿«é€Ÿå“åº”...")
        state['current_step'] = "quick_response"
        
        try:
            # ä½¿ç”¨ LLM å›ç­”ç®€å•é—®é¢˜
            messages = [
                SystemMessage(content="ä½ æ˜¯æ¯”ç‰¹å¸å¸‚åœºåˆ†æä¸“å®¶ã€‚ç®€æ´å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"),
                HumanMessage(content=state['user_input'])
            ]
            
            response = self.llm.invoke(messages)
            state['response'] = response.content
            state['messages'].append(AIMessage(content=response.content))
            
        except Exception as e:
            state['response'] = f"æ— æ³•å›ç­”: {str(e)}"
        
        return state
    
    # ==================== è¾…åŠ©å‡½æ•° ====================
    
    def _extract_key_stats(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ä» DataFrame æå–å…³é”®ç»Ÿè®¡æ•°æ®"""
        try:
            latest = df.iloc[-1]
            prev_week = df.iloc[-7] if len(df) >= 7 else df.iloc[0]
            
            stats = {
                'price': {
                    'current': float(latest.get('market_Close', 0)),
                    'week_start': float(prev_week.get('market_Close', 0)),
                    'week_return': ((float(latest.get('market_Close', 0)) / 
                                    float(prev_week.get('market_Close', 1))) - 1) * 100
                },
                'regime': {
                    'current_regime': str(latest.get('market_regime_cn', 'N/A'))
                },
                'volatility': {
                    'current': float(latest.get('RealizedVol_30d', 0)) * 100
                },
                'sentiment': {
                    'current': float(latest.get('Fear_Greed_Index', 50)),
                    'current_category': self._get_fg_category(float(latest.get('Fear_Greed_Index', 50)))
                },
                'capital': {
                    'main_behavior': str(latest.get('Main_Behavior_CN', 'N/A'))
                }
            }
            
            return stats
            
        except Exception as e:
            self.log(f"æå–ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def _get_fg_category(self, fg: float) -> str:
        """è·å– Fear & Greed ç±»åˆ«"""
        if fg < 25: return "æåº¦ææ…Œ"
        elif fg < 45: return "ææ…Œ"
        elif fg < 55: return "ä¸­æ€§"
        elif fg < 75: return "è´ªå©ª"
        else: return "æåº¦è´ªå©ª"
    
    # ==================== å·¥ä½œæµæ„å»º ====================
    
    def _build_workflow(self) -> StateGraph:
        """æ„å»º LangGraph å·¥ä½œæµ"""
        self.log("æ„å»º LangGraph å·¥ä½œæµ...")
        
        # åˆ›å»ºå·¥ä½œæµå›¾
        workflow = StateGraph(ResearchState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("route_task", self._node_route_task)
        workflow.add_node("collect_data", self._node_collect_data)
        workflow.add_node("process_data", self._node_process_data)
        workflow.add_node("analyze_regime", self._node_analyze_regime)
        workflow.add_node("analyze_volatility", self._node_analyze_volatility)
        workflow.add_node("analyze_sentiment", self._node_analyze_sentiment)
        workflow.add_node("analyze_capital", self._node_analyze_capital)
        workflow.add_node("generate_insights", self._node_generate_insights)
        workflow.add_node("generate_report", self._node_generate_report)
        workflow.add_node("quick_response", self._node_quick_response)
        
        # å®šä¹‰å·¥ä½œæµï¼ˆåŸºäºä»»åŠ¡ç±»å‹çš„æ¡ä»¶è·¯ç”±ï¼‰
        workflow.set_entry_point("route_task")
        
        # æ¡ä»¶è·¯ç”±
        def should_do_full_analysis(state: ResearchState) -> str:
            """åˆ¤æ–­æ˜¯å¦éœ€è¦å®Œæ•´åˆ†æ"""
            task_type = state.get('task_type', 'full_analysis')
            
            if task_type == "quick_query":
                return "quick"
            else:
                return "full"
        
        workflow.add_conditional_edges(
            "route_task",
            should_do_full_analysis,
            {
                "quick": "quick_response",
                "full": "collect_data"
            }
        )
        
        # å®Œæ•´åˆ†ææµç¨‹
        workflow.add_edge("collect_data", "process_data")
        workflow.add_edge("process_data", "analyze_regime")
        workflow.add_edge("analyze_regime", "analyze_volatility")
        workflow.add_edge("analyze_volatility", "analyze_sentiment")
        workflow.add_edge("analyze_sentiment", "analyze_capital")
        workflow.add_edge("analyze_capital", "generate_insights")
        workflow.add_edge("generate_insights", "generate_report")
        
        # ç»“æŸèŠ‚ç‚¹
        workflow.add_edge("generate_report", END)
        workflow.add_edge("quick_response", END)
        
        self.log("âœ… å·¥ä½œæµæ„å»ºå®Œæˆ")
        
        return workflow
    
    # ==================== å…¬å…±æ¥å£ ====================
    
    def run(self, user_input: str = "ç”Ÿæˆå®Œæ•´å¸‚åœºåˆ†ææŠ¥å‘Š") -> Dict[str, Any]:
        """
        è¿è¡Œ Agent
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
        
        Returns:
            åŒ…å«åˆ†æç»“æœçš„å­—å…¸
        """
        self.log(f"\n{'='*70}")
        self.log(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {user_input}")
        self.log(f"{'='*70}\n")
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = ResearchState(
            user_input=user_input,
            task_type="",
            market_data=None,
            processed_data=None,
            regime_analysis=None,
            volatility_analysis=None,
            sentiment_analysis=None,
            capital_analysis=None,
            ai_insights=None,
            report=None,
            response=None,
            messages=[],
            current_step="initialized",
            error=None
        )
        
        # æ‰§è¡Œå·¥ä½œæµ
        try:
            result = self.app.invoke(initial_state)
            
            self.log(f"\n{'='*70}")
            self.log("âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
            self.log(f"{'='*70}\n")
            
            return result
            
        except Exception as e:
            self.log(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            return {
                'error': str(e),
                'response': f"æ‰§è¡Œå¤±è´¥: {str(e)}"
            }
    
    def chat(self, message: str) -> str:
        """
        å¯¹è¯æ¥å£
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
        
        Returns:
            Agent çš„å›å¤
        """
        result = self.run(message)
        return result.get('response', 'æ— å“åº”')


def main():
    """æµ‹è¯•å‡½æ•°"""
    # Force UTF-8 output for Windows
    if sys.platform == "win32":
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    
    print("\n" + "=" * 70)
    print("  Bitcoin Research Agent - LangGraph å®ç°")
    print("=" * 70 + "\n")
    
    try:
        # åˆ›å»º Agent
        agent = BitcoinResearchAgent(
            llm_provider="openai",
            llm_model="gpt-4o-mini",
            verbose=True
        )
        
        print("\nâœ… Agent åˆ›å»ºæˆåŠŸï¼\n")
        
        # æµ‹è¯•ï¼šç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        print("æµ‹è¯• 1: ç”Ÿæˆå®Œæ•´å¸‚åœºåˆ†ææŠ¥å‘Š")
        print("-" * 70)
        
        result = agent.run("ç”Ÿæˆæœ¬å‘¨æ¯”ç‰¹å¸å¸‚åœºåˆ†ææŠ¥å‘Š")
        
        if result.get('report'):
            print("\nğŸ“Š æŠ¥å‘Šé¢„è§ˆ:")
            print(result['report'][:1000])
            print("\n[... å®Œæ•´æŠ¥å‘Šå·²ç”Ÿæˆ ...]")
        else:
            print(f"\nå“åº”: {result.get('response', 'æ— å“åº”')}")
        
        print("\n" + "=" * 70)
        print("æµ‹è¯•å®Œæˆï¼")
        print("=" * 70)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        print("\næç¤º:")
        print("1. ç¡®ä¿å·²è®¾ç½® OPENAI_API_KEY")
        print("2. ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")


if __name__ == '__main__':
    main()

