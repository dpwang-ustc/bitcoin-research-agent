"""
WAL-12 å®è§‚ä¸Žæ–°é—»æ•°æ®æ”¶é›†æµ‹è¯•

æµ‹è¯•å†…å®¹ï¼š
1. å®è§‚æ•°æ®æ”¶é›†å™¨æµ‹è¯•ï¼ˆDXY, VIX, é»„é‡‘ç­‰ï¼‰
2. æ–°é—»æ•°æ®æ”¶é›†å™¨æµ‹è¯•ï¼ˆRSS, CryptoPanic, NewsAPIï¼‰
3. æƒ…æ„Ÿåˆ†æžå™¨æµ‹è¯•
4. æ•°æ®èšåˆå™¨é›†æˆæµ‹è¯•
5. æ•°æ®ä¿å­˜å’ŒåŠ è½½æµ‹è¯•
"""

import sys
import io
import os
import pandas as pd
from datetime import datetime, timedelta

# Windows UTF-8 è¾“å‡º
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from data.macro_collector import MacroCollector
from data.news_collector import NewsCollector
from analysis.sentiment_analyzer import SentimentAnalyzer
from data.market_data_aggregator import MarketDataAggregator


def print_section_header(title):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print("\n" + "=" * 60)
    print(f"{' ' * ((60 - len(title)) // 2)}{title}")
    print("=" * 60)


def test_macro_collector():
    """æµ‹è¯•å®è§‚æ•°æ®æ”¶é›†å™¨"""
    print_section_header("æµ‹è¯• 1: å®è§‚æ•°æ®æ”¶é›†å™¨")
    
    collector = MacroCollector()
    
    try:
        # æµ‹è¯•ç¾Žå…ƒæŒ‡æ•°
        print("\n1.1 æµ‹è¯•ç¾Žå…ƒæŒ‡æ•° (DXY):")
        dxy = collector.get_indicator('dxy', start_date='2025-10-01')
        
        if not dxy.empty and 'Close' in dxy.columns:
            print(f"âœ“ DXY æ•°æ®èŽ·å–æˆåŠŸ: {len(dxy)} æ¡")
            print(f"  æœ€æ–°ä»·æ ¼: {dxy['Close'].iloc[-1]:.2f}")
            return_dxy = True
        else:
            print("âš ï¸  DXY æ•°æ®èŽ·å–å¤±è´¥ï¼ˆå¯èƒ½çš„ç½‘ç»œé—®é¢˜ï¼‰")
            return_dxy = False
        
        # æµ‹è¯• VIX
        print("\n1.2 æµ‹è¯• VIX ææ…ŒæŒ‡æ•°:")
        vix = collector.get_indicator('vix', start_date='2025-10-01')
        
        if not vix.empty and 'Close' in vix.columns:
            print(f"âœ“ VIX æ•°æ®èŽ·å–æˆåŠŸ: {len(vix)} æ¡")
            print(f"  æœ€æ–°æŒ‡æ•°: {vix['Close'].iloc[-1]:.2f}")
            return_vix = True
        else:
            print("âš ï¸  VIX æ•°æ®èŽ·å–å¤±è´¥")
            return_vix = False
        
        # æµ‹è¯•é»„é‡‘ä»·æ ¼
        print("\n1.3 æµ‹è¯•é»„é‡‘ä»·æ ¼:")
        gold = collector.get_indicator('gold', start_date='2025-10-01')
        
        if not gold.empty and 'Close' in gold.columns:
            print(f"âœ“ é»„é‡‘æ•°æ®èŽ·å–æˆåŠŸ: {len(gold)} æ¡")
            print(f"  æœ€æ–°ä»·æ ¼: ${gold['Close'].iloc[-1]:.2f}")
            return_gold = True
        else:
            print("âš ï¸  é»„é‡‘æ•°æ®èŽ·å–å¤±è´¥")
            return_gold = False
        
        # è‡³å°‘ä¸€ä¸ªæˆåŠŸå°±ç®—é€šè¿‡
        return return_dxy or return_vix or return_gold
        
    except Exception as e:
        print(f"âœ— å®è§‚æ•°æ®æ”¶é›†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_news_collector():
    """æµ‹è¯•æ–°é—»æ•°æ®æ”¶é›†å™¨"""
    print_section_header("æµ‹è¯• 2: æ–°é—»æ•°æ®æ”¶é›†å™¨")
    
    collector = NewsCollector()
    
    try:
        # æµ‹è¯• RSS Feedsï¼ˆå…è´¹ï¼Œæœ€ç¨³å®šï¼‰
        print("\n2.1 æµ‹è¯• RSS Feeds:")
        
        # æµ‹è¯•å•ä¸ª RSS Feed
        feeds_to_test = ['coindesk', 'cointelegraph']
        rss_success = False
        
        for feed_name in feeds_to_test:
            df = collector.get_rss_feed(feed_name, max_entries=5)
            if not df.empty:
                print(f"âœ“ {feed_name.upper()} RSS Feed æˆåŠŸ: {len(df)} æ¡æ–°é—»")
                if len(df) > 0:
                    print(f"  æœ€æ–°æ ‡é¢˜: {df['title'].iloc[0][:60]}...")
                rss_success = True
                break
            else:
                print(f"âš ï¸  {feed_name.upper()} RSS Feed å¤±è´¥")
        
        # æµ‹è¯• CryptoPanicï¼ˆéœ€è¦ API Keyï¼‰
        print("\n2.2 æµ‹è¯• CryptoPanic API:")
        
        if collector.cryptopanic_key:
            cp_df = collector.get_cryptopanic_news(filter_type='hot', limit=5)
            if not cp_df.empty:
                print(f"âœ“ CryptoPanic æ•°æ®èŽ·å–æˆåŠŸ: {len(cp_df)} æ¡æ–°é—»")
                cp_success = True
            else:
                print("âš ï¸  CryptoPanic æ•°æ®ä¸ºç©º")
                cp_success = False
        else:
            print("âš ï¸  è·³è¿‡ï¼ˆæœªè®¾ç½® CRYPTOPANIC_API_KEYï¼‰")
            cp_success = True  # è·³è¿‡ä¸ç®—å¤±è´¥
        
        # æµ‹è¯• NewsAPIï¼ˆéœ€è¦ API Keyï¼‰
        print("\n2.3 æµ‹è¯• NewsAPI:")
        
        if collector.newsapi_key:
            news_df = collector.get_newsapi_articles(query='bitcoin', page_size=5)
            if not news_df.empty:
                print(f"âœ“ NewsAPI æ•°æ®èŽ·å–æˆåŠŸ: {len(news_df)} æ¡æ–‡ç« ")
                newsapi_success = True
            else:
                print("âš ï¸  NewsAPI æ•°æ®ä¸ºç©º")
                newsapi_success = False
        else:
            print("âš ï¸  è·³è¿‡ï¼ˆæœªè®¾ç½® NEWSAPI_KEYï¼‰")
            newsapi_success = True  # è·³è¿‡ä¸ç®—å¤±è´¥
        
        # è‡³å°‘ RSS æˆåŠŸå³å¯
        return rss_success
        
    except Exception as e:
        print(f"âœ— æ–°é—»æ•°æ®æ”¶é›†å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_sentiment_analyzer():
    """æµ‹è¯•æƒ…æ„Ÿåˆ†æžå™¨"""
    print_section_header("æµ‹è¯• 3: æƒ…æ„Ÿåˆ†æžå™¨")
    
    try:
        analyzer = SentimentAnalyzer(use_vader=True, use_textblob=True)
        
        # æµ‹è¯•æ ·æœ¬
        test_texts = [
            "Bitcoin surges to new all-time high as institutions buy",
            "Crypto market crashes amid regulatory fears",
            "Bitcoin price remains stable",
        ]
        
        print("\n3.1 å•æ¡æ–‡æœ¬æƒ…æ„Ÿåˆ†æž:")
        all_analyzed = True
        
        for text in test_texts:
            result = analyzer.analyze_text(text)
            if result and 'sentiment' in result:
                print(f"âœ“ æ–‡æœ¬: {text[:50]}...")
                print(f"  æƒ…æ„Ÿ: {result['sentiment']} (å¾—åˆ†: {result['score']:.3f})")
            else:
                print(f"âœ— åˆ†æžå¤±è´¥: {text[:50]}...")
                all_analyzed = False
        
        # æµ‹è¯•æ‰¹é‡åˆ†æž
        print("\n3.2 æ‰¹é‡æƒ…æ„Ÿåˆ†æž:")
        
        df = pd.DataFrame({
            'title': test_texts,
            'published_at': pd.date_range(start='2025-10-23', periods=3, freq='D')
        })
        df.set_index('published_at', inplace=True)
        
        df_analyzed = analyzer.analyze_dataframe(df, text_column='title')
        
        if 'sentiment' in df_analyzed.columns and 'sentiment_score' in df_analyzed.columns:
            print(f"âœ“ æ‰¹é‡åˆ†æžæˆåŠŸ: {len(df_analyzed)} æ¡")
            print(f"\næƒ…æ„Ÿåˆ†å¸ƒ:")
            print(df_analyzed['sentiment'].value_counts())
            return True
        else:
            print("âœ— æ‰¹é‡åˆ†æžå¤±è´¥")
            return False
        
    except Exception as e:
        print(f"âœ— æƒ…æ„Ÿåˆ†æžå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_aggregator_integration():
    """æµ‹è¯•æ•°æ®èšåˆå™¨é›†æˆ"""
    print_section_header("æµ‹è¯• 4: æ•°æ®èšåˆå™¨é›†æˆ")
    
    try:
        aggregator = MarketDataAggregator()
        
        print("\næ­£åœ¨æ”¶é›†ç»¼åˆæ•°æ®ï¼ˆåŒ…å«å®è§‚å’Œæ–°é—»ï¼‰...")
        print("æ³¨æ„ï¼šè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´...\n")
        
        data_dict = aggregator.get_comprehensive_data(
            days_back=7,
            include_funding=False,  # è·³è¿‡å¯èƒ½å¤±è´¥çš„ Binance
            include_market_info=True,
            include_onchain=False,  # è·³è¿‡é“¾ä¸Šæ•°æ®åŠ å¿«æµ‹è¯•
            include_macro=True,
            include_news=True
        )
        
        if data_dict:
            print(f"\nâœ“ æ•°æ®èšåˆæˆåŠŸï¼Œå…± {len(data_dict)} ä¸ªæ•°æ®é›†")
            
            # æ£€æŸ¥å®è§‚æ•°æ®
            macro_keys = [k for k in data_dict.keys() if k.startswith('macro_')]
            if macro_keys:
                print(f"\nå®è§‚æ•°æ®é›† ({len(macro_keys)}):")
                for key in macro_keys:
                    print(f"  âœ“ {key}: {len(data_dict[key])} æ¡")
            else:
                print("\nâš ï¸  æœªæ‰¾åˆ°å®è§‚æ•°æ®é›†")
            
            # æ£€æŸ¥æ–°é—»æ•°æ®
            news_keys = [k for k in data_dict.keys() if k.startswith('news_')]
            if news_keys:
                print(f"\næ–°é—»æ•°æ®é›† ({len(news_keys)}):")
                for key in news_keys:
                    print(f"  âœ“ {key}: {len(data_dict[key])} æ¡")
            else:
                print("\nâš ï¸  æœªæ‰¾åˆ°æ–°é—»æ•°æ®é›†")
            
            # è‡³å°‘æœ‰å®è§‚æˆ–æ–°é—»æ•°æ®
            return len(macro_keys) > 0 or len(news_keys) > 0
        else:
            print("âœ— æ•°æ®èšåˆå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âœ— æ•°æ®èšåˆå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_data_save_load():
    """æµ‹è¯•æ•°æ®ä¿å­˜å’ŒåŠ è½½"""
    print_section_header("æµ‹è¯• 5: æ•°æ®ä¿å­˜å’ŒåŠ è½½")
    
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs('data/raw', exist_ok=True)
        
        # èŽ·å–ä¸€äº›å®è§‚æ•°æ®
        print("\n5.1 èŽ·å–å¹¶ä¿å­˜å®è§‚æ•°æ®:")
        collector = MacroCollector()
        
        macro_data = collector.get_all_macro_indicators(
            start_date='2025-10-20',
            indicators=['vix', 'gold']
        )
        
        saved_count = 0
        for indicator, df in macro_data.items():
            if not df.empty:
                filename = f'data/raw/macro_{indicator}_test.csv'
                df.to_csv(filename)
                print(f"âœ“ ä¿å­˜: {filename}")
                saved_count += 1
                
                # éªŒè¯åŠ è½½
                df_loaded = pd.read_csv(filename, index_col=0, parse_dates=True)
                if len(df_loaded) > 0:
                    print(f"  éªŒè¯åŠ è½½: {len(df_loaded)} è¡Œ")
        
        # èŽ·å–å¹¶ä¿å­˜æ–°é—»æ•°æ®
        print("\n5.2 èŽ·å–å¹¶ä¿å­˜æ–°é—»æ•°æ®:")
        news_collector = NewsCollector()
        
        rss_df = news_collector.get_rss_feed('coindesk', max_entries=5)
        
        if not rss_df.empty:
            filename = 'data/raw/news_coindesk_test.csv'
            rss_df.to_csv(filename)
            print(f"âœ“ ä¿å­˜: {filename}")
            
            # éªŒè¯åŠ è½½
            df_loaded = pd.read_csv(filename, index_col=0, parse_dates=True)
            print(f"  éªŒè¯åŠ è½½: {len(df_loaded)} è¡Œ")
            saved_count += 1
        
        return saved_count > 0
        
    except Exception as e:
        print(f"âœ— æ•°æ®ä¿å­˜/åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 60)
    print("  WAL-12 å®è§‚ä¸Žæ–°é—»æ•°æ® - å®Œæ•´æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    print()
    
    results = {}
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    print("å¼€å§‹æµ‹è¯•...\n")
    
    results['å®è§‚æ•°æ®æ”¶é›†å™¨'] = test_macro_collector()
    results['æ–°é—»æ•°æ®æ”¶é›†å™¨'] = test_news_collector()
    results['æƒ…æ„Ÿåˆ†æžå™¨'] = test_sentiment_analyzer()
    results['æ•°æ®èšåˆå™¨é›†æˆ'] = test_aggregator_integration()
    results['æ•°æ®ä¿å­˜åŠ è½½'] = test_data_save_load()
    
    # æ±‡æ€»ç»“æžœ
    print_section_header("WAL-12 æµ‹è¯•ç»“æžœæ±‡æ€»")
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    print()
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status}  {test_name}")
    
    print()
    print("=" * 60)
    if passed == total:
        print(f"ðŸŽ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼({passed}/{total})")
    else:
        print(f"âš ï¸  éƒ¨åˆ†æµ‹è¯•é€šè¿‡ ({passed}/{total})")
    print("=" * 60)
    print()
    
    # é¢å¤–è¯´æ˜Ž
    print("ðŸ“ æ³¨æ„äº‹é¡¹:")
    print("- å®è§‚æ•°æ®æ¥è‡ª yfinanceï¼ˆå…è´¹ï¼Œæ— éœ€ API Keyï¼‰")
    print("- RSS Feeds å®Œå…¨å…è´¹ï¼Œæ— éœ€ API Key")
    print("- CryptoPanic éœ€è¦å…è´¹æ³¨å†Œ: https://cryptopanic.com/developers/api/")
    print("- NewsAPI éœ€è¦å…è´¹æ³¨å†Œ: https://newsapi.org/register")
    print("- æƒ…æ„Ÿåˆ†æžæ”¯æŒåŸºç¡€æ–¹æ³•ï¼ˆæ— éœ€å®‰è£…é¢å¤–åº“ï¼‰")
    print("- å¯é€‰å®‰è£… VADER å’Œ TextBlob æå‡å‡†ç¡®åº¦")
    print()
    
    return passed >= 3  # è‡³å°‘3ä¸ªæµ‹è¯•é€šè¿‡


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

